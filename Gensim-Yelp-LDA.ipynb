{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to install these packages in terminal in your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/CAMPUS/nabieir/NLP_LDA\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "curr_dir = os.getcwd()\n",
    "import pickle\n",
    "import csv\n",
    "print(curr_dir)\n",
    "\n",
    "print(sys.version_info[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## import time\n",
    "from pathlib import Path\n",
    "import nltk; nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genism\n",
    "Here we add Gensim libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import gensim \n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import coherencemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim # don't skip this \n",
    "# import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable logging for gensim - optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does LDA do?\n",
    "LDA’s approach to topic modeling is it considers each document as a collection of topics in a certain proportion. And each topic as a collection of keywords, again, in a certain proportion.\n",
    "\n",
    "Once you provide the algorithm with the number of topics, all it does it to rearrange the topics distribution within the documents and keywords distribution within the topics to obtain a good composition of topic-keywords distribution.\n",
    "\n",
    "When I say topic, what is it actually and how it is represented?\n",
    "\n",
    "A topic is nothing but a collection of dominant keywords that are typical representatives. Just by looking at the keywords, you can identify what the topic is all about.\n",
    "\n",
    "The following are key factors to obtaining good segregation topics:\n",
    "\n",
    "1. The quality of processed text data.\n",
    "2. The variety of topics the text talks about.\n",
    "3. The choice of topic modeling algorithm.\n",
    "4. The number of topics fed to the algorithm.\n",
    "5. The algorithms tuning parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Stopwords\n",
    "We have already downloaded the stopwords. Let’s import them and make it available in stop_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/CAMPUS/nabieir/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay, the file exists!\n"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "import os.path \n",
    "filename = curr_dir + \"/data/clinical_reviews_only_english.txt\"\n",
    "if not os.path.isfile(filename):\n",
    "    print(\"Oops, file doesn't exist!\")\n",
    "else:\n",
    "    print(\"Yay, the file exists!\")\n",
    "\n",
    "with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "    data = f.read().splitlines()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savetofile (fpath,data):\n",
    "    with open(fpath,\"wt\") as f:\n",
    "        for sent in data:\n",
    "            f.write(sent + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting non-English sentences \n",
    "We can use polyglot or langdetect package. polyglot is faster and can be used for name-entity detection as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detecting non-english sentences\n",
    "# from polyglot.detect import Detector\n",
    "# non_english = {}\n",
    "\n",
    "# for i,sent in enumerate(data):\n",
    "#     detector = Detector(sent,quiet=True)\n",
    "#     if detector.language.code != 'en':\n",
    "#         non_english[i] = sent\n",
    "# print(len(non_english),len(data))\n",
    "\n",
    "##### This is another package langdetect but it is slower !!!\n",
    "\n",
    "# from langdetect import detect\n",
    "\n",
    "# non_english = []\n",
    "\n",
    "# for i,sent in enumerate(data):\n",
    "#     detector = detect(sent)\n",
    "#     if detector != 'en':\n",
    "#         non_english.append(sent)\n",
    "#         print(i,sent)\n",
    "        \n",
    "# print(len(non_english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save only english text as a new source text data \n",
    "\n",
    "# for index in sorted(non_english, reverse=True):     #Delete detected non_english sentences\n",
    "#     del data[index]\n",
    "    \n",
    "# with open(curr_dir + \"/data/clinical_reviews_only_english.txt\",\"wt\") as f:\n",
    "#     for sent in data:\n",
    "#         f.write(sent + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find abbriviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = \"salam che LSB khoobi ?\"\n",
    "# test = re.findall('([A-Z]+)', A)\n",
    "# print(test)\n",
    "# import re\n",
    "# for i,sent in enumerate(data):\n",
    "#     abbr = re.findall(r'\\b[A-Z][A-Z]+\\b',sent)\n",
    "#     if len(abbr) > 0:\n",
    "#         print (i,abbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"lenght of data was :\" + str(len(data)))\n",
    "# # Deleting very small sentences (Document)\n",
    "# #data1 = [1, 3, 6, 35, 3 ,47,9,15]\n",
    "# # print(data1)\n",
    "# i = 0\n",
    "# for n in data[:]:\n",
    "#     if len(n) < 200:\n",
    "#         print(n)\n",
    "#         data.remove(n)\n",
    "        \n",
    "# savetofile(curr_dir + \"/data/clinical_reviews_only_english_200char.txt\",data)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import Patient review data from Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CountChar(List):      # funtion to count all the characters in a list\n",
    "#     sum = 0\n",
    "#     for line in List:\n",
    "#         sum += len(line)\n",
    "#     return sum\n",
    "# # OriginalLenght = sum(len(line) for line in List) # this is more pythonic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Tokenize words and Clean-up text\n",
    "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether.\n",
    "\n",
    "Gensim’s simple_preprocess() is great for this. Additionally I have set deacc=True to remove the punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for i,sentence in enumerate(sentences):\n",
    "#         if i % 100000 == 0:    # this is just for debugging when the database is very big\n",
    "#             print (i/100000)\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "# TODO count the number of sentences         \n",
    "data_words = list(sent_to_words(data))\n",
    "#data_words = list(filter(None, data_words)) #_ remove empty cells in the list\n",
    "#data = list(filter(None, data)) #_ remove empty cells in the list\n",
    "#print(len(data))\n",
    "# TODO count the number of sentences maybe compare them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inthenameofgodr', 'the', 'lord', 'name', 'of', 'god']\n"
     ]
    }
   ],
   "source": [
    "print(gensim.utils.simple_preprocess('InthenameofGodR the, 1lord name of God!', deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(sum(len(sen) for sen in data))\n",
    "# print(CountChar(data)) \n",
    "# # print(sum(len(words) for words in data_words))\n",
    "# print(CountChar(data_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Creating Bigram and Trigram Models\n",
    "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring.\n",
    "\n",
    "Some examples in our patient review data are: ‘weight_loss’, ‘weigth_training’, 'most_likely' etc.\n",
    "\n",
    "Gensim’s Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold. The higher the values of these param, the harder it is for words to be combined to bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CAMPUS/nabieir/anaconda3/envs/python3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=80)# higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "# Print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(bigram_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bigram_mod[data_words[59]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Remove Stopwords, Make Bigrams and Lemmatize\n",
    "The bigrams model is ready. Let’s define the functions to remove the stopwords, make bigrams and lemmatization and call them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s call the functions in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Create the Dictionary and Corpus needed for Topic Modeling\n",
    "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "#_ Joiining words together to build sentences this will be used later \n",
    "data = [' '.join(lemma) for lemma in data_lemmatized] \n",
    "\n",
    "# View\n",
    "# print(corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd         #Find the term-frequency in dictionary        \n",
    "# # vocab = list(id2word.values()) #list of terms in the dictionary\n",
    "# vocab_tf = [dict(i) for i in corpus]\n",
    "# vocab_tf = list(pd.DataFrame(vocab_tf).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "# # rare_tokens = [index for index in range(len(vocab_tf)) if vocab_tf[index]<4] #index of the word that appear less than 3 times in the corpus\n",
    "# print(type(vocab_tf))\n",
    "# print(id2word[max(range(len(vocab_tf)), key=vocab_tf.__getitem__)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([id2word[index] for index in one_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can see a human-readable form of the corpus itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "# [[(id2word[id], freq) for id, freq in cp] for cp in corpus[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15580\n",
      "15580\n",
      "54.70783055198973\n"
     ]
    }
   ],
   "source": [
    "# print(len(data_lemmatized))\n",
    "# print(len(corpus))\n",
    "# AVG = sum (len(Sen) for Sen in data_lemmatized)/len(data_lemmatized)\n",
    "# print(AVG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LDA Mallet Model\n",
    "Gensim provides a wrapper to implement Mallet’s LDA from within Gensim itself. You only need to download the zipfile, unzip it and provide the path to mallet in the unzipped directory to gensim.models.wrappers.LdaMallet. See how I have done this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "# mallet_path = '/home/CAMPUS/nabieir/anaconda3/mallet-2.0.8/bin/mallet' # update this path\n",
    "# ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the optimal number of topics for LDA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = '/home/CAMPUS/nabieir/anaconda3/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \n",
    "    NOTE, The Coherence calcualation has been commented out, and calculated separately later\n",
    "    \"\"\"\n",
    "    #coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        start_time = time.time()\n",
    "        print(\"Training LDA with %d topics starts ...\" % num_topics )\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        #coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        #coherence_ldamallet = coherence_model.get_coherence()\n",
    "        #coherence_values.append(coherence_ldamallet)\n",
    "        print(\"LDA training time = %s min\" % ((time.time() - start_time)/60))\n",
    "        #print('Coherence Score: ', coherence_ldamallet)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LDA with 10 topics starts ...\n",
      "LDA training time = 0.7892612854639689 min\n",
      "Training LDA with 20 topics starts ...\n",
      "LDA training time = 0.7959242184956868 min\n",
      "Training LDA with 30 topics starts ...\n",
      "LDA training time = 0.7975939472516378 min\n",
      "Training LDA with 40 topics starts ...\n",
      "LDA training time = 0.8321049451828003 min\n",
      "Training LDA with 50 topics starts ...\n",
      "LDA training time = 0.8111048777898152 min\n",
      "Training LDA with 60 topics starts ...\n",
      "LDA training time = 0.818677278359731 min\n",
      "Training LDA with 70 topics starts ...\n",
      "LDA training time = 0.8444813172022502 min\n",
      "Training LDA with 80 topics starts ...\n",
      "LDA training time = 1.0202747583389282 min\n",
      "Training LDA with 90 topics starts ...\n",
      "LDA training time = 1.0588663578033448 min\n",
      "Training LDA with 100 topics starts ...\n",
      "LDA training time = 1.0926095525423685 min\n",
      "Training LDA with 110 topics starts ...\n",
      "LDA training time = 1.184247612953186 min\n",
      "Training LDA with 120 topics starts ...\n",
      "LDA training time = 1.1479732751846314 min\n",
      "Training LDA with 130 topics starts ...\n",
      "LDA training time = 1.1672910054524739 min\n",
      "Training LDA with 140 topics starts ...\n",
      "LDA training time = 1.1388929208119711 min\n",
      "Training LDA with 150 topics starts ...\n",
      "LDA training time = 1.1530652244885762 min\n",
      "Training LDA with 160 topics starts ...\n",
      "LDA training time = 1.1489051143328348 min\n",
      "Training LDA with 170 topics starts ...\n",
      "LDA training time = 1.088626221815745 min\n",
      "Training LDA with 180 topics starts ...\n",
      "LDA training time = 1.1158790826797484 min\n",
      "Training LDA with 190 topics starts ...\n",
      "LDA training time = 1.1118141611417134 min\n",
      "Training LDA with 200 topics starts ...\n",
      "LDA training time = 1.1161449392636618 min\n",
      "Training LDA with 210 topics starts ...\n",
      "LDA training time = 1.1297075907389322 min\n"
     ]
    }
   ],
   "source": [
    "model_list = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=10, limit=220, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save our models \n",
    "import os\n",
    "directory = curr_dir + '/MalletModels/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "for i,model in enumerate(model_list):\n",
    "    filename =  directory + str(i) + \".mallet\" \n",
    "    model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load our models \n",
    "# model_list = []\n",
    "# for i in range(20):\n",
    "#     filename =  current + \"/MalletModels/\" + str(i) + \".mallet\"\n",
    "#     model_list.append(gensim.models.wrappers.LdaMallet.load(filename,mmap='r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20928"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(model_list)\n",
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_values = []\n",
    "for Mmodel in model_list:\n",
    "    coherence_model = gensim.models.CoherenceModel(model=Mmodel, texts=data_lemmatized, dictionary=id2word, coherence='c_v', topn = 10)\n",
    "    coherence_ldamallet = coherence_model.get_coherence()\n",
    "    coherence_values.append(coherence_ldamallet)\n",
    "    print('Coherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# This is to save the Coherence_values to a text file\n",
    "print(len(coherence_values))\n",
    "with open(curr_dir + \"/MalletModels/CV_Coherence_topn10.txt\",\"wt\") as f:\n",
    "    for C in coherence_values:\n",
    "        f.write(str(C) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Coherence_values form a text file to a list\n",
    "# coherence_values = []\n",
    "# with open(\"/home/CAMPUS/nabieir/HDD/LDA/Gensim-LDA/MalletModels/Coherences.txt\", \"r\") as f:\n",
    "#     for line in f:coherence_values.append(float(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "limit=220; start=10; step=10;\n",
    "x = range(start, limit, step)\n",
    "num_topic = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 20))\n",
    "# ax.grid(True)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score (C_V)\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(num_topic, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('life', 0.08423256563053631), ('health', 0.04469318730874537), ('year', 0.037928813013367695), ('change', 0.03511032372362699), ('condition', 0.026896440650668384), ('treat', 0.020293122886133032), ('healthy', 0.02021259462071187), ('live', 0.017957803188919312), ('save', 0.017555161861813495), ('trust', 0.013689805121597681)]\n"
     ]
    }
   ],
   "source": [
    "#type(optimal_model)\n",
    "#optimal_model.show_topic(20,topn=10)\n",
    "print(topic_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('life', 0.08423256563053631),\n",
       " ('health', 0.04469318730874537),\n",
       " ('year', 0.037928813013367695),\n",
       " ('change', 0.03511032372362699),\n",
       " ('condition', 0.026896440650668384),\n",
       " ('treat', 0.020293122886133032),\n",
       " ('healthy', 0.02021259462071187),\n",
       " ('live', 0.017957803188919312),\n",
       " ('save', 0.017555161861813495),\n",
       " ('trust', 0.013689805121597681),\n",
       " ('meet', 0.011273957158962795),\n",
       " ('heart', 0.01111290062812047),\n",
       " ('continue', 0.010871315831856982),\n",
       " ('worth', 0.01079078756643582),\n",
       " ('person', 0.010710259301014656),\n",
       " ('quality', 0.010388146239330005),\n",
       " ('good', 0.009421807054276051),\n",
       " ('age', 0.009260750523433725),\n",
       " ('man', 0.009180222258012563),\n",
       " ('improve', 0.0090996939925914),\n",
       " ('support', 0.008858109196327912),\n",
       " ('grateful', 0.008697052665485585),\n",
       " ('approach', 0.00853599613464326),\n",
       " ('diagnose', 0.008455467869222097),\n",
       " ('big', 0.008374939603800934),\n",
       " ('knowledge', 0.007730713480431631),\n",
       " ('true', 0.007489128684168143),\n",
       " ('entire', 0.007247543887904655),\n",
       " ('disease', 0.007086487357062329),\n",
       " ('stress', 0.007005959091641166),\n",
       " ('miss', 0.006683846029956515),\n",
       " ('young', 0.00595909164116605),\n",
       " ('valley', 0.00595909164116605),\n",
       " ('anxiety', 0.005798035110323723),\n",
       " ('method', 0.005153808986954421),\n",
       " ('holistic', 0.005073280721533258),\n",
       " ('michael', 0.005073280721533258),\n",
       " ('educate', 0.004912224190690932),\n",
       " ('struggle', 0.00483169592526977),\n",
       " ('learn', 0.00483169592526977),\n",
       " ('maintain', 0.00483169592526977),\n",
       " ('solution', 0.004751167659848607),\n",
       " ('discover', 0.004751167659848607),\n",
       " ('illness', 0.004670639394427444),\n",
       " ('world', 0.004590111129006281),\n",
       " ('lifestyle', 0.004429054598163956),\n",
       " ('past', 0.004348526332742793),\n",
       " ('affect', 0.004348526332742793),\n",
       " ('chronic', 0.00426799806732163),\n",
       " ('practitioner', 0.00426799806732163),\n",
       " ('nutrition', 0.00426799806732163),\n",
       " ('mental', 0.004187469801900467),\n",
       " ('suffer', 0.004187469801900467),\n",
       " ('figure', 0.004106941536479304),\n",
       " ('regularly', 0.003945885005636978),\n",
       " ('career', 0.003945885005636978),\n",
       " ('forward', 0.003945885005636978),\n",
       " ('phillip', 0.003784828474794653),\n",
       " ('important', 0.00370430020937349),\n",
       " ('interest', 0.00370430020937349),\n",
       " ('hope', 0.0036237719439523274),\n",
       " ('strongly', 0.0036237719439523274),\n",
       " ('long_term', 0.0036237719439523274),\n",
       " ('manage', 0.0036237719439523274),\n",
       " ('habit', 0.0035432436785311646),\n",
       " ('milne', 0.0033821871476888386),\n",
       " ('advice', 0.003301658882267676),\n",
       " ('path', 0.003221130616846513),\n",
       " ('diet', 0.003221130616846513),\n",
       " ('fear', 0.003221130616846513),\n",
       " ('rely', 0.0031406023514253503),\n",
       " ('create', 0.0031406023514253503),\n",
       " ('aspect', 0.0030600740860041876),\n",
       " ('track', 0.002979545820583025),\n",
       " ('sincerely', 0.002979545820583025),\n",
       " ('full', 0.002979545820583025),\n",
       " ('natural', 0.0028990175551618616),\n",
       " ('guidance', 0.0028990175551618616),\n",
       " ('brilliant', 0.002818489289740699),\n",
       " ('journey', 0.002818489289740699),\n",
       " ('physically', 0.002818489289740699),\n",
       " ('utilize', 0.002737961024319536),\n",
       " ('ailment', 0.0026574327588983733),\n",
       " ('thrilled', 0.0026574327588983733),\n",
       " ('put', 0.0026574327588983733),\n",
       " ('sullivan', 0.0025769044934772106),\n",
       " ('fry', 0.0025769044934772106),\n",
       " ('lose', 0.002496376228056048),\n",
       " ('bunch', 0.002496376228056048),\n",
       " ('literally', 0.002496376228056048),\n",
       " ('diabetic', 0.002496376228056048),\n",
       " ('effort', 0.002496376228056048),\n",
       " ('grow', 0.002415847962634885),\n",
       " ('related', 0.002335319697213722),\n",
       " ('develop', 0.002335319697213722),\n",
       " ('shea', 0.002335319697213722),\n",
       " ('naturopath', 0.002335319697213722),\n",
       " ('faith', 0.002335319697213722),\n",
       " ('fatigue', 0.002254791431792559),\n",
       " ('naturopathic', 0.002254791431792559),\n",
       " ('complicated', 0.002254791431792559),\n",
       " ('potential', 0.0021742631663713963),\n",
       " ('fortunate', 0.0020937349009502336),\n",
       " ('every_penny', 0.0020937349009502336),\n",
       " ('setup', 0.0020937349009502336),\n",
       " ('luca', 0.0020937349009502336),\n",
       " ('expertise', 0.002013206635529071),\n",
       " ('guide', 0.002013206635529071),\n",
       " ('difficulty', 0.002013206635529071),\n",
       " ('holistic_approach', 0.002013206635529071),\n",
       " ('proud', 0.0019326783701079078),\n",
       " ('profession', 0.0019326783701079078),\n",
       " ('emotional', 0.0019326783701079078),\n",
       " ('technology', 0.0019326783701079078),\n",
       " ('forever_grateful', 0.001852150104686745),\n",
       " ('focused', 0.001852150104686745),\n",
       " ('key', 0.001852150104686745),\n",
       " ('spending', 0.0017716218392655823),\n",
       " ('combine', 0.0017716218392655823),\n",
       " ('depression', 0.0017716218392655823),\n",
       " ('disorder', 0.0017716218392655823),\n",
       " ('unique', 0.0016910935738444193),\n",
       " ('integrative', 0.0016910935738444193),\n",
       " ('gift', 0.0016910935738444193),\n",
       " ('gary', 0.0016910935738444193),\n",
       " ('remedy', 0.0016910935738444193),\n",
       " ('effectively', 0.0016105653084232566),\n",
       " ('difficult', 0.0016105653084232566),\n",
       " ('box', 0.0016105653084232566),\n",
       " ('forever', 0.0015300370430020938),\n",
       " ('feeling', 0.0015300370430020938),\n",
       " ('connection', 0.0015300370430020938),\n",
       " ('radio', 0.0014495087775809308),\n",
       " ('importance', 0.0014495087775809308),\n",
       " ('teaching', 0.0014495087775809308),\n",
       " ('sincere', 0.001368980512159768),\n",
       " ('action', 0.001368980512159768),\n",
       " ('hamilton', 0.0012884522467386053),\n",
       " ('genius', 0.0012884522467386053),\n",
       " ('breast_cancer', 0.0012884522467386053),\n",
       " ('convince', 0.0012884522467386053),\n",
       " ('produce', 0.0012884522467386053),\n",
       " ('hopeful', 0.0012884522467386053),\n",
       " ('laurie', 0.0012079239813174425),\n",
       " ('endure', 0.0012079239813174425),\n",
       " ('cutting_edge', 0.0012079239813174425),\n",
       " ('frye', 0.0012079239813174425),\n",
       " ('afraid', 0.0012079239813174425),\n",
       " ('lyme', 0.0012079239813174425),\n",
       " ('power', 0.0012079239813174425),\n",
       " ('rick', 0.0011273957158962795),\n",
       " ('exos', 0.0011273957158962795),\n",
       " ('invasive', 0.0011273957158962795),\n",
       " ('relative', 0.0011273957158962795),\n",
       " ('mentally', 0.0011273957158962795),\n",
       " ('christy', 0.0011273957158962795),\n",
       " ('attack', 0.0010468674504751168),\n",
       " ('lyme_disease', 0.0010468674504751168),\n",
       " ('luxury', 0.0010468674504751168),\n",
       " ('assembly_line', 0.0010468674504751168),\n",
       " ('evolve', 0.0010468674504751168),\n",
       " ('integrate', 0.0010468674504751168),\n",
       " ('diabete', 0.0010468674504751168),\n",
       " ('nutritionist', 0.0010468674504751168),\n",
       " ('conventional', 0.0010468674504751168),\n",
       " ('encourage', 0.0010468674504751168),\n",
       " ('honestly', 0.0010468674504751168),\n",
       " ('tonya', 0.0009663391850539539),\n",
       " ('insight', 0.0009663391850539539),\n",
       " ('disability', 0.0009663391850539539),\n",
       " ('empower', 0.0009663391850539539),\n",
       " ('freedom', 0.0009663391850539539),\n",
       " ('gifted', 0.0009663391850539539),\n",
       " ('complicate', 0.0009663391850539539),\n",
       " ('western', 0.0009663391850539539),\n",
       " ('woolston', 0.0009663391850539539),\n",
       " ('logan', 0.0008858109196327911),\n",
       " ('select', 0.0008858109196327911),\n",
       " ('north', 0.0008858109196327911),\n",
       " ('life_saver', 0.0008858109196327911),\n",
       " ('dizziness', 0.0008858109196327911),\n",
       " ('top', 0.0008858109196327911),\n",
       " ('someday', 0.0008858109196327911),\n",
       " ('god_bless', 0.0008858109196327911),\n",
       " ('hopeless', 0.0008858109196327911),\n",
       " ('carolina', 0.0008858109196327911),\n",
       " ('western_medicine', 0.0008858109196327911),\n",
       " ('ohio', 0.0008858109196327911),\n",
       " ('cheer', 0.0008858109196327911),\n",
       " ('syndrome', 0.0008858109196327911),\n",
       " ('talent', 0.0008858109196327911),\n",
       " ('apparent', 0.0008858109196327911),\n",
       " ('heart_disease', 0.0008052826542116283),\n",
       " ('assumption', 0.0008052826542116283),\n",
       " ('compare', 0.0008052826542116283),\n",
       " ('cure', 0.0008052826542116283),\n",
       " ('award', 0.0008052826542116283),\n",
       " ('travis', 0.0008052826542116283),\n",
       " ('thing', 0.0008052826542116283),\n",
       " ('episode', 0.0008052826542116283),\n",
       " ('curtis', 0.0008052826542116283),\n",
       " ('ago', 0.0008052826542116283),\n",
       " ('lupus', 0.0008052826542116283),\n",
       " ('passion', 0.0008052826542116283),\n",
       " ('neurological', 0.0008052826542116283),\n",
       " ('food_allergie', 0.0008052826542116283),\n",
       " ('cain', 0.0008052826542116283),\n",
       " ('exacerbate', 0.0007247543887904654),\n",
       " ('exhaust', 0.0007247543887904654),\n",
       " ('intuition', 0.0007247543887904654),\n",
       " ('genetic', 0.0007247543887904654),\n",
       " ('attentiveness', 0.0007247543887904654),\n",
       " ('sandy', 0.0007247543887904654),\n",
       " ('wellbeing', 0.0007247543887904654),\n",
       " ('short_term', 0.0007247543887904654),\n",
       " ('occasion', 0.0007247543887904654),\n",
       " ('warner', 0.0007247543887904654),\n",
       " ('diamond', 0.0007247543887904654),\n",
       " ('dietary', 0.0007247543887904654),\n",
       " ('sommer', 0.0007247543887904654),\n",
       " ('loss', 0.0007247543887904654),\n",
       " ('maternity', 0.0007247543887904654),\n",
       " ('badly', 0.0007247543887904654),\n",
       " ('cheryl', 0.0007247543887904654),\n",
       " ('adhd', 0.0007247543887904654),\n",
       " ('shreder', 0.0007247543887904654),\n",
       " ('possibility', 0.0006442261233693026),\n",
       " ('improved_dramatically', 0.0006442261233693026),\n",
       " ('uplift', 0.0006442261233693026),\n",
       " ('drastic', 0.0006442261233693026),\n",
       " ('choose', 0.0006442261233693026),\n",
       " ('larry', 0.0006442261233693026),\n",
       " ('autoimmune', 0.0006442261233693026),\n",
       " ('unhealthy', 0.0006442261233693026),\n",
       " ('pronounce', 0.0006442261233693026),\n",
       " ('threat', 0.0006442261233693026),\n",
       " ('recognition', 0.0006442261233693026),\n",
       " ('macrotherapy', 0.0006442261233693026),\n",
       " ('gradually', 0.0006442261233693026),\n",
       " ('nonexistent', 0.0006442261233693026),\n",
       " ('experiment', 0.0005636978579481398),\n",
       " ('obtain', 0.0005636978579481398),\n",
       " ('simply', 0.0005636978579481398),\n",
       " ('committed', 0.0005636978579481398),\n",
       " ('rough', 0.0005636978579481398),\n",
       " ('irk', 0.0005636978579481398),\n",
       " ('size_fit', 0.0005636978579481398),\n",
       " ('ptsd', 0.0005636978579481398),\n",
       " ('contemplate', 0.0005636978579481398),\n",
       " ('model', 0.0005636978579481398),\n",
       " ('supposedly', 0.0005636978579481398),\n",
       " ('vast_knowledge', 0.0005636978579481398),\n",
       " ('david_stone', 0.0005636978579481398),\n",
       " ('scope', 0.0005636978579481398),\n",
       " ('making', 0.0005636978579481398),\n",
       " ('open_minded', 0.0005636978579481398),\n",
       " ('lakeside', 0.00048316959252697695),\n",
       " ('alter', 0.00048316959252697695),\n",
       " ('tanya', 0.00048316959252697695),\n",
       " ('stable', 0.00048316959252697695),\n",
       " ('lioce', 0.00048316959252697695),\n",
       " ('judgment', 0.00048316959252697695),\n",
       " ('pharmaceutical', 0.00048316959252697695),\n",
       " ('counsel', 0.00048316959252697695),\n",
       " ('interfere', 0.00048316959252697695),\n",
       " ('ozone', 0.00048316959252697695),\n",
       " ('paula', 0.00048316959252697695),\n",
       " ('costly', 0.00048316959252697695),\n",
       " ('respectful', 0.00048316959252697695),\n",
       " ('bounce', 0.00048316959252697695),\n",
       " ('due', 0.00048316959252697695),\n",
       " ('highway', 0.00048316959252697695),\n",
       " ('instance', 0.00048316959252697695),\n",
       " ('progressively', 0.00040264132710581414),\n",
       " ('rock', 0.00040264132710581414),\n",
       " ('exhaustion', 0.00040264132710581414),\n",
       " ('hurt', 0.00040264132710581414),\n",
       " ('diabet', 0.00040264132710581414),\n",
       " ('obese', 0.00040264132710581414),\n",
       " ('intern', 0.00040264132710581414),\n",
       " ('physiology', 0.00040264132710581414),\n",
       " ('united_state', 0.00040264132710581414),\n",
       " ('validate', 0.00040264132710581414),\n",
       " ('define', 0.00040264132710581414),\n",
       " ('longtime', 0.00040264132710581414),\n",
       " ('nichola', 0.00040264132710581414),\n",
       " ('elis', 0.00040264132710581414),\n",
       " ('herniated_discs', 0.00040264132710581414),\n",
       " ('opportunity', 0.00040264132710581414),\n",
       " ('kyle', 0.00040264132710581414),\n",
       " ('lederman', 0.00040264132710581414),\n",
       " ('forum', 0.00040264132710581414),\n",
       " ('regime', 0.00040264132710581414),\n",
       " ('kylie', 0.00040264132710581414),\n",
       " ('mollen', 0.00040264132710581414),\n",
       " ('separate_occasion', 0.00040264132710581414),\n",
       " ('wellbe', 0.00040264132710581414),\n",
       " ('kathy', 0.00040264132710581414),\n",
       " ('depress', 0.00040264132710581414),\n",
       " ('differently', 0.00040264132710581414),\n",
       " ('pounds_lighter', 0.00040264132710581414),\n",
       " ('methodical', 0.0003221130616846513),\n",
       " ('bottner', 0.0003221130616846513),\n",
       " ('vds', 0.0003221130616846513),\n",
       " ('buroff', 0.0003221130616846513),\n",
       " ('adrenal', 0.0003221130616846513),\n",
       " ('asian', 0.0003221130616846513),\n",
       " ('meaningful', 0.0003221130616846513),\n",
       " ('sad', 0.0003221130616846513),\n",
       " ('zip', 0.0003221130616846513),\n",
       " ('testimonial', 0.0003221130616846513),\n",
       " ('component', 0.0003221130616846513),\n",
       " ('vegan', 0.0003221130616846513),\n",
       " ('celiac', 0.0003221130616846513),\n",
       " ('glad', 0.0003221130616846513),\n",
       " ('san_diego', 0.0003221130616846513),\n",
       " ('compound', 0.0003221130616846513),\n",
       " ('check_up', 0.0003221130616846513),\n",
       " ('ecstatic', 0.0003221130616846513),\n",
       " ('intelligent', 0.0003221130616846513),\n",
       " ('nutritional', 0.0003221130616846513),\n",
       " ('bedside_manner', 0.0003221130616846513),\n",
       " ('toxic', 0.0003221130616846513),\n",
       " ('michlin', 0.0003221130616846513),\n",
       " ('kirk', 0.0003221130616846513),\n",
       " ('strict', 0.0003221130616846513),\n",
       " ('bedridden', 0.0003221130616846513),\n",
       " ('specialty', 0.0003221130616846513),\n",
       " ('marlena', 0.0003221130616846513),\n",
       " ('fir', 0.0003221130616846513),\n",
       " ('barrow', 0.0003221130616846513),\n",
       " ('presentation', 0.00024158479626348848),\n",
       " ('messaging', 0.00024158479626348848),\n",
       " ('fav', 0.00024158479626348848),\n",
       " ('schooling', 0.00024158479626348848),\n",
       " ('mend', 0.00024158479626348848),\n",
       " ('butt', 0.00024158479626348848),\n",
       " ('wise', 0.00024158479626348848),\n",
       " ('thrive', 0.00024158479626348848),\n",
       " ('mimic', 0.00024158479626348848),\n",
       " ('remission', 0.00024158479626348848),\n",
       " ('overbill', 0.00024158479626348848),\n",
       " ('mold', 0.00024158479626348848),\n",
       " ('valvular', 0.00024158479626348848),\n",
       " ('celia', 0.00024158479626348848),\n",
       " ('powerful', 0.00024158479626348848),\n",
       " ('enjoy', 0.00024158479626348848),\n",
       " ('barne', 0.00024158479626348848),\n",
       " ('doubt', 0.00024158479626348848),\n",
       " ('counseling', 0.00024158479626348848),\n",
       " ('judgement', 0.00024158479626348848),\n",
       " ('eternally_grateful', 0.00024158479626348848),\n",
       " ('lively', 0.00024158479626348848),\n",
       " ('prevail', 0.00024158479626348848),\n",
       " ('fam', 0.00024158479626348848),\n",
       " ('persuade', 0.00024158479626348848),\n",
       " ('delve', 0.00024158479626348848),\n",
       " ('worthwhile', 0.00024158479626348848),\n",
       " ('ankle_sprain', 0.00024158479626348848),\n",
       " ('ricky', 0.00024158479626348848),\n",
       " ('building', 0.00024158479626348848),\n",
       " ('adorn', 0.00024158479626348848),\n",
       " ('interject', 0.00024158479626348848),\n",
       " ('shy', 0.00024158479626348848),\n",
       " ('charismatic', 0.00024158479626348848),\n",
       " ('reliant', 0.00024158479626348848),\n",
       " ('strongly_suggest', 0.00024158479626348848),\n",
       " ('quantity', 0.00024158479626348848),\n",
       " ('exterior', 0.00024158479626348848),\n",
       " ('polar', 0.00024158479626348848),\n",
       " ('judge', 0.00024158479626348848),\n",
       " ('bizarre', 0.00024158479626348848),\n",
       " ('mexico', 0.00024158479626348848),\n",
       " ('fast_forward', 0.00024158479626348848),\n",
       " ('hfm', 0.00016105653084232566),\n",
       " ('purposeful', 0.00016105653084232566),\n",
       " ('practically', 0.00016105653084232566),\n",
       " ('andreasen', 0.00016105653084232566),\n",
       " ('changed', 0.00016105653084232566),\n",
       " ('clue', 0.00016105653084232566),\n",
       " ('parental', 0.00016105653084232566),\n",
       " ('lieu', 0.00016105653084232566),\n",
       " ('aron', 0.00016105653084232566),\n",
       " ('increase', 0.00016105653084232566),\n",
       " ('tool', 0.00016105653084232566),\n",
       " ('inherit', 0.00016105653084232566),\n",
       " ('groundbreak', 0.00016105653084232566),\n",
       " ('tap', 0.00016105653084232566),\n",
       " ('indebt', 0.00016105653084232566),\n",
       " ('broad', 0.00016105653084232566),\n",
       " ('aid', 0.00016105653084232566),\n",
       " ('west', 0.00016105653084232566),\n",
       " ('kindly', 0.00016105653084232566),\n",
       " ('january', 0.00016105653084232566),\n",
       " ('heck', 0.00016105653084232566),\n",
       " ('cirelli', 0.00016105653084232566),\n",
       " ('reap', 0.00016105653084232566),\n",
       " ('aaron', 0.00016105653084232566),\n",
       " ('body', 0.00016105653084232566),\n",
       " ('tindall', 0.00016105653084232566),\n",
       " ('reluctance', 0.00016105653084232566),\n",
       " ('ramsey', 0.00016105653084232566),\n",
       " ('noticed', 0.00016105653084232566),\n",
       " ('target', 0.00016105653084232566),\n",
       " ('monistat', 0.00016105653084232566),\n",
       " ('professor', 0.00016105653084232566),\n",
       " ('pointing', 0.00016105653084232566),\n",
       " ('leakage', 0.00016105653084232566),\n",
       " ('guatham', 0.00016105653084232566),\n",
       " ('productive', 0.00016105653084232566),\n",
       " ('simultaneously', 0.00016105653084232566),\n",
       " ('bring', 0.00016105653084232566),\n",
       " ('addressed', 0.00016105653084232566),\n",
       " ('alright', 0.00016105653084232566),\n",
       " ('foot', 0.00016105653084232566),\n",
       " ('misdiagnosis', 0.00016105653084232566),\n",
       " ('butcher', 0.00016105653084232566),\n",
       " ('waster', 0.00016105653084232566),\n",
       " ('impede', 0.00016105653084232566),\n",
       " ('band_aid', 0.00016105653084232566),\n",
       " ('allot', 0.00016105653084232566),\n",
       " ('incur', 0.00016105653084232566),\n",
       " ('lessen', 0.00016105653084232566),\n",
       " ('stalk', 0.00016105653084232566),\n",
       " ('disappointed', 0.00016105653084232566),\n",
       " ('longevity', 0.00016105653084232566),\n",
       " ('surgery', 0.00016105653084232566),\n",
       " ('miracle', 0.00016105653084232566),\n",
       " ('gail', 0.00016105653084232566),\n",
       " ('expense', 0.00016105653084232566),\n",
       " ('teenager', 0.00016105653084232566),\n",
       " ('sabrena', 0.00016105653084232566),\n",
       " ('philip', 0.00016105653084232566),\n",
       " ('undo', 0.00016105653084232566),\n",
       " ('basketball', 0.00016105653084232566),\n",
       " ('spew', 0.00016105653084232566),\n",
       " ('dramatic', 0.00016105653084232566),\n",
       " ('constantine', 0.00016105653084232566),\n",
       " ('xiao', 0.00016105653084232566),\n",
       " ('confidence', 0.00016105653084232566),\n",
       " ('fast', 0.00016105653084232566),\n",
       " ('delight', 0.00016105653084232566),\n",
       " ('welborn', 0.00016105653084232566),\n",
       " ('hormonal', 0.00016105653084232566),\n",
       " ('vita', 0.00016105653084232566),\n",
       " ('mercede', 0.00016105653084232566),\n",
       " ('sounding', 0.00016105653084232566),\n",
       " ('short', 0.00016105653084232566),\n",
       " ('crawl', 0.00016105653084232566),\n",
       " ('mr', 0.00016105653084232566),\n",
       " ('greed', 0.00016105653084232566),\n",
       " ('brechler', 8.052826542116283e-05),\n",
       " ('karinne', 8.052826542116283e-05),\n",
       " ('dvfm', 8.052826542116283e-05),\n",
       " ('scanning', 8.052826542116283e-05),\n",
       " ('jogging', 8.052826542116283e-05),\n",
       " ('getto', 8.052826542116283e-05),\n",
       " ('champion', 8.052826542116283e-05),\n",
       " ('psychotherapist', 8.052826542116283e-05),\n",
       " ('cara', 8.052826542116283e-05),\n",
       " ('altought', 8.052826542116283e-05),\n",
       " ('personal_trainer', 8.052826542116283e-05),\n",
       " ('categorize', 8.052826542116283e-05),\n",
       " ('throttle', 8.052826542116283e-05),\n",
       " ('blinder', 8.052826542116283e-05),\n",
       " ('scalp', 8.052826542116283e-05),\n",
       " ('identification', 8.052826542116283e-05),\n",
       " ('spiral', 8.052826542116283e-05),\n",
       " ('richly', 8.052826542116283e-05),\n",
       " ('institution', 8.052826542116283e-05),\n",
       " ('puncual', 8.052826542116283e-05),\n",
       " ('suffocate', 8.052826542116283e-05),\n",
       " ('scholarship', 8.052826542116283e-05),\n",
       " ('academy', 8.052826542116283e-05),\n",
       " ('wood', 8.052826542116283e-05),\n",
       " ('indie', 8.052826542116283e-05),\n",
       " ('worsen', 8.052826542116283e-05),\n",
       " ('simin', 8.052826542116283e-05),\n",
       " ('bodycombat', 8.052826542116283e-05),\n",
       " ('chirp', 8.052826542116283e-05),\n",
       " ('wexford', 8.052826542116283e-05),\n",
       " ('cost', 8.052826542116283e-05),\n",
       " ('gosomewhereelse', 8.052826542116283e-05),\n",
       " ('affirmation', 8.052826542116283e-05),\n",
       " ('refreshment', 8.052826542116283e-05),\n",
       " ('unnoticed', 8.052826542116283e-05),\n",
       " ('ism', 8.052826542116283e-05),\n",
       " ('fibromyagia', 8.052826542116283e-05),\n",
       " ('reye', 8.052826542116283e-05),\n",
       " ('heh', 8.052826542116283e-05),\n",
       " ('patrice', 8.052826542116283e-05),\n",
       " ('lawana', 8.052826542116283e-05),\n",
       " ('responsibility', 8.052826542116283e-05),\n",
       " ('accommodating', 8.052826542116283e-05),\n",
       " ('obsessively', 8.052826542116283e-05),\n",
       " ('piss', 8.052826542116283e-05),\n",
       " ('chigger', 8.052826542116283e-05),\n",
       " ('overbearing', 8.052826542116283e-05),\n",
       " ('melt', 8.052826542116283e-05),\n",
       " ('sheepish', 8.052826542116283e-05),\n",
       " ('acuball', 8.052826542116283e-05),\n",
       " ('catalogue', 8.052826542116283e-05),\n",
       " ('cobra', 8.052826542116283e-05),\n",
       " ('ricardo', 8.052826542116283e-05),\n",
       " ('skim', 8.052826542116283e-05),\n",
       " ('inappropriate', 8.052826542116283e-05),\n",
       " ('bronze', 8.052826542116283e-05),\n",
       " ('overjoyed', 8.052826542116283e-05),\n",
       " ('merhdad', 8.052826542116283e-05),\n",
       " ('washed', 8.052826542116283e-05),\n",
       " ('fairhill', 8.052826542116283e-05),\n",
       " ('trouble_breathing', 8.052826542116283e-05),\n",
       " ('coincidently', 8.052826542116283e-05),\n",
       " ('farxiga', 8.052826542116283e-05),\n",
       " ('epidemic', 8.052826542116283e-05),\n",
       " ('negatively', 8.052826542116283e-05),\n",
       " ('compute', 8.052826542116283e-05),\n",
       " ('embarrass', 8.052826542116283e-05),\n",
       " ('ntice', 8.052826542116283e-05),\n",
       " ('kali', 8.052826542116283e-05),\n",
       " ('mountainful', 8.052826542116283e-05),\n",
       " ('remix', 8.052826542116283e-05),\n",
       " ('entertaining', 8.052826542116283e-05),\n",
       " ('merchandise', 8.052826542116283e-05),\n",
       " ('prop', 8.052826542116283e-05),\n",
       " ('downstream', 8.052826542116283e-05),\n",
       " ('dialogue', 8.052826542116283e-05),\n",
       " ('rusk', 8.052826542116283e-05),\n",
       " ('sideline', 8.052826542116283e-05),\n",
       " ('master', 8.052826542116283e-05),\n",
       " ('unclean', 8.052826542116283e-05),\n",
       " ('aswell', 8.052826542116283e-05),\n",
       " ('bing', 8.052826542116283e-05),\n",
       " ('pause', 8.052826542116283e-05),\n",
       " ('defib', 8.052826542116283e-05),\n",
       " ('prescriptive', 8.052826542116283e-05),\n",
       " ('ppo', 8.052826542116283e-05),\n",
       " ('umc', 8.052826542116283e-05),\n",
       " ('laminectomy', 8.052826542116283e-05),\n",
       " ('tearful', 8.052826542116283e-05),\n",
       " ('schelomp', 8.052826542116283e-05),\n",
       " ('pouty', 8.052826542116283e-05),\n",
       " ('issuing', 8.052826542116283e-05),\n",
       " ('robax', 8.052826542116283e-05),\n",
       " ('fundamentally', 8.052826542116283e-05),\n",
       " ('prescripe', 8.052826542116283e-05),\n",
       " ('geoffrey', 8.052826542116283e-05),\n",
       " ('perceptive', 8.052826542116283e-05),\n",
       " ('joceline', 8.052826542116283e-05),\n",
       " ('awsome', 8.052826542116283e-05),\n",
       " ('perrin', 8.052826542116283e-05),\n",
       " ('footrest', 8.052826542116283e-05),\n",
       " ('enterprise', 8.052826542116283e-05),\n",
       " ('fiend', 8.052826542116283e-05),\n",
       " ('refrigerator', 8.052826542116283e-05),\n",
       " ('remark', 8.052826542116283e-05),\n",
       " ('aftercare', 8.052826542116283e-05),\n",
       " ('corpse', 8.052826542116283e-05),\n",
       " ('intelligence', 8.052826542116283e-05),\n",
       " ('issur', 8.052826542116283e-05),\n",
       " ('spree', 8.052826542116283e-05),\n",
       " ('staffi', 8.052826542116283e-05),\n",
       " ('camelback', 8.052826542116283e-05),\n",
       " ('cohen', 8.052826542116283e-05),\n",
       " ('summer', 8.052826542116283e-05),\n",
       " ('dic', 8.052826542116283e-05),\n",
       " ('syncope', 8.052826542116283e-05),\n",
       " ('express', 8.052826542116283e-05),\n",
       " ('peruse', 8.052826542116283e-05),\n",
       " ('fran', 8.052826542116283e-05),\n",
       " ('feng', 8.052826542116283e-05),\n",
       " ('handbook', 8.052826542116283e-05),\n",
       " ('zeke', 8.052826542116283e-05),\n",
       " ('lindsay', 8.052826542116283e-05),\n",
       " ('microphone', 8.052826542116283e-05),\n",
       " ('recurrent', 8.052826542116283e-05),\n",
       " ('termination', 8.052826542116283e-05),\n",
       " ('rationally', 8.052826542116283e-05),\n",
       " ('curtesy', 8.052826542116283e-05),\n",
       " ('reenergize', 8.052826542116283e-05),\n",
       " ('ppd', 8.052826542116283e-05),\n",
       " ('rbc', 8.052826542116283e-05),\n",
       " ('outdated', 8.052826542116283e-05),\n",
       " ('rawson', 8.052826542116283e-05),\n",
       " ('itheycould', 8.052826542116283e-05),\n",
       " ('vehicular', 8.052826542116283e-05),\n",
       " ('psyche', 8.052826542116283e-05),\n",
       " ('reprehensible', 8.052826542116283e-05),\n",
       " ('beauty', 8.052826542116283e-05),\n",
       " ('leap', 8.052826542116283e-05),\n",
       " ('allay', 8.052826542116283e-05),\n",
       " ('unavoidable', 8.052826542116283e-05),\n",
       " ('tbw', 8.052826542116283e-05),\n",
       " ('hammersmtih', 8.052826542116283e-05),\n",
       " ('roomy', 8.052826542116283e-05),\n",
       " ('unrelenting', 8.052826542116283e-05),\n",
       " ('stocker', 8.052826542116283e-05),\n",
       " ('outdoors', 8.052826542116283e-05),\n",
       " ('burroff', 8.052826542116283e-05),\n",
       " ('wagon', 8.052826542116283e-05),\n",
       " ('beaman', 8.052826542116283e-05),\n",
       " ('regular', 8.052826542116283e-05),\n",
       " ('supreme', 8.052826542116283e-05),\n",
       " ('diginity', 8.052826542116283e-05),\n",
       " ('urgicare', 8.052826542116283e-05),\n",
       " ('coax', 8.052826542116283e-05),\n",
       " ('grace', 8.052826542116283e-05),\n",
       " ('stroke', 8.052826542116283e-05),\n",
       " ('focuss', 8.052826542116283e-05),\n",
       " ('fibromyalgia', 8.052826542116283e-05),\n",
       " ('ocatillo', 8.052826542116283e-05),\n",
       " ('noon', 8.052826542116283e-05),\n",
       " ('ulcer', 8.052826542116283e-05),\n",
       " ('dysplasia', 8.052826542116283e-05),\n",
       " ('manufacture', 8.052826542116283e-05),\n",
       " ('immense', 8.052826542116283e-05),\n",
       " ('rehap', 8.052826542116283e-05),\n",
       " ('sameer', 8.052826542116283e-05),\n",
       " ('smug', 8.052826542116283e-05),\n",
       " ('burket', 8.052826542116283e-05),\n",
       " ('penny', 8.052826542116283e-05),\n",
       " ('envision', 8.052826542116283e-05),\n",
       " ('blake', 8.052826542116283e-05),\n",
       " ('coz', 8.052826542116283e-05),\n",
       " ('jessica', 8.052826542116283e-05),\n",
       " ('unsuspecting', 8.052826542116283e-05),\n",
       " ('sargent', 8.052826542116283e-05),\n",
       " ('crusade', 8.052826542116283e-05),\n",
       " ('haag', 8.052826542116283e-05),\n",
       " ('decad', 8.052826542116283e-05),\n",
       " ('cord', 8.052826542116283e-05),\n",
       " ('suburb', 8.052826542116283e-05),\n",
       " ('slimm', 8.052826542116283e-05),\n",
       " ('interpret', 8.052826542116283e-05),\n",
       " ('affectionate', 8.052826542116283e-05),\n",
       " ('jt', 8.052826542116283e-05),\n",
       " ('evaluating', 8.052826542116283e-05),\n",
       " ('determining', 8.052826542116283e-05),\n",
       " ('bioidentical', 8.052826542116283e-05),\n",
       " ('lmao', 8.052826542116283e-05),\n",
       " ('cubicle', 8.052826542116283e-05),\n",
       " ('fart', 8.052826542116283e-05),\n",
       " ('blog', 8.052826542116283e-05),\n",
       " ('innate', 8.052826542116283e-05),\n",
       " ('dungeon', 8.052826542116283e-05),\n",
       " ('lighter', 8.052826542116283e-05),\n",
       " ('takn', 8.052826542116283e-05),\n",
       " ('awasome', 8.052826542116283e-05),\n",
       " ('losing', 8.052826542116283e-05),\n",
       " ('aches_pain', 8.052826542116283e-05),\n",
       " ('expediency', 8.052826542116283e-05),\n",
       " ('psychiatry', 8.052826542116283e-05),\n",
       " ('cultural', 8.052826542116283e-05),\n",
       " ('dawson', 8.052826542116283e-05),\n",
       " ('loo', 8.052826542116283e-05),\n",
       " ('bellevue', 8.052826542116283e-05),\n",
       " ('needed', 8.052826542116283e-05),\n",
       " ('bugger', 8.052826542116283e-05),\n",
       " ('complement', 8.052826542116283e-05),\n",
       " ('diplomatic', 8.052826542116283e-05),\n",
       " ('sulli', 8.052826542116283e-05),\n",
       " ('decrease', 8.052826542116283e-05),\n",
       " ('paternal', 8.052826542116283e-05),\n",
       " ('scholar', 8.052826542116283e-05),\n",
       " ('rid', 8.052826542116283e-05),\n",
       " ('dwindle', 8.052826542116283e-05),\n",
       " ('friendly', 8.052826542116283e-05),\n",
       " ('duck', 8.052826542116283e-05),\n",
       " ('reversal', 8.052826542116283e-05),\n",
       " ('scapulothoracic', 8.052826542116283e-05),\n",
       " ('lois', 8.052826542116283e-05),\n",
       " ('norman', 8.052826542116283e-05),\n",
       " ('cecelia', 8.052826542116283e-05),\n",
       " ('irvine', 8.052826542116283e-05),\n",
       " ('tricia', 8.052826542116283e-05),\n",
       " ('amazement', 8.052826542116283e-05),\n",
       " ('upset', 8.052826542116283e-05),\n",
       " ('spouse', 8.052826542116283e-05),\n",
       " ('schroder', 8.052826542116283e-05),\n",
       " ('marry', 8.052826542116283e-05),\n",
       " ('nationwide', 8.052826542116283e-05),\n",
       " ('gospel', 8.052826542116283e-05),\n",
       " ('earnestly', 8.052826542116283e-05),\n",
       " ('gpm', 8.052826542116283e-05),\n",
       " ('scatterbrain', 8.052826542116283e-05),\n",
       " ('spasming', 8.052826542116283e-05),\n",
       " ('mtn', 8.052826542116283e-05),\n",
       " ('purist', 8.052826542116283e-05),\n",
       " ('instagram', 8.052826542116283e-05),\n",
       " ('lifelong', 8.052826542116283e-05),\n",
       " ('sunglass', 8.052826542116283e-05),\n",
       " ('innocent', 8.052826542116283e-05),\n",
       " ('popularity', 8.052826542116283e-05),\n",
       " ('rupter', 8.052826542116283e-05),\n",
       " ('singing', 8.052826542116283e-05),\n",
       " ('rightful', 8.052826542116283e-05),\n",
       " ('radical', 8.052826542116283e-05),\n",
       " ('avenger', 8.052826542116283e-05),\n",
       " ('pecient', 8.052826542116283e-05),\n",
       " ('muscular', 8.052826542116283e-05),\n",
       " ('asshol', 8.052826542116283e-05),\n",
       " ('gynocological', 8.052826542116283e-05),\n",
       " ('fur', 8.052826542116283e-05),\n",
       " ('nasa', 8.052826542116283e-05),\n",
       " ('outline', 8.052826542116283e-05),\n",
       " ('leaf', 8.052826542116283e-05),\n",
       " ('sickening', 8.052826542116283e-05),\n",
       " ('holy_cow', 8.052826542116283e-05),\n",
       " ('dummy', 8.052826542116283e-05),\n",
       " ('berated', 8.052826542116283e-05),\n",
       " ('chos', 8.052826542116283e-05),\n",
       " ('carelessly', 8.052826542116283e-05),\n",
       " ('carmichael', 8.052826542116283e-05),\n",
       " ('overseas', 8.052826542116283e-05),\n",
       " ('abroad', 8.052826542116283e-05),\n",
       " ('dara', 8.052826542116283e-05),\n",
       " ('interference', 8.052826542116283e-05),\n",
       " ('fertility', 8.052826542116283e-05),\n",
       " ('azsds', 8.052826542116283e-05),\n",
       " ('gramma', 8.052826542116283e-05),\n",
       " ('coach', 8.052826542116283e-05),\n",
       " ('whoa', 8.052826542116283e-05),\n",
       " ('thinga', 8.052826542116283e-05),\n",
       " ('unconscious', 8.052826542116283e-05),\n",
       " ('gaston', 8.052826542116283e-05),\n",
       " ('measuring', 8.052826542116283e-05),\n",
       " ('licata', 8.052826542116283e-05),\n",
       " ('indulge', 8.052826542116283e-05),\n",
       " ('ravage', 8.052826542116283e-05),\n",
       " ('compliment', 8.052826542116283e-05),\n",
       " ('dawn', 8.052826542116283e-05),\n",
       " ('duplicate', 8.052826542116283e-05),\n",
       " ('denerol', 8.052826542116283e-05),\n",
       " ('choir', 8.052826542116283e-05),\n",
       " ('quiz', 8.052826542116283e-05),\n",
       " ('strangely', 8.052826542116283e-05),\n",
       " ('guatemalan', 8.052826542116283e-05),\n",
       " ('converse', 8.052826542116283e-05),\n",
       " ('garden', 8.052826542116283e-05),\n",
       " ('cum', 8.052826542116283e-05),\n",
       " ('neurospinal', 8.052826542116283e-05),\n",
       " ('content', 8.052826542116283e-05),\n",
       " ('crumble', 8.052826542116283e-05),\n",
       " ('participant', 8.052826542116283e-05),\n",
       " ('dissolve', 8.052826542116283e-05),\n",
       " ('violent', 8.052826542116283e-05),\n",
       " ('psalm', 8.052826542116283e-05),\n",
       " ('splurge', 8.052826542116283e-05),\n",
       " ('rehearsal', 8.052826542116283e-05),\n",
       " ('dustraction', 8.052826542116283e-05),\n",
       " ('snd', 8.052826542116283e-05),\n",
       " ('dump', 8.052826542116283e-05),\n",
       " ('otw', 8.052826542116283e-05),\n",
       " ('therapuetic', 8.052826542116283e-05),\n",
       " ('lucero', 8.052826542116283e-05),\n",
       " ('hefty', 8.052826542116283e-05),\n",
       " ('upstairs', 8.052826542116283e-05),\n",
       " ('nj', 8.052826542116283e-05),\n",
       " ('fine', 8.052826542116283e-05),\n",
       " ('kristian', 8.052826542116283e-05),\n",
       " ('irate', 8.052826542116283e-05),\n",
       " ('ergonomic', 8.052826542116283e-05),\n",
       " ('hippocratic_oath', 8.052826542116283e-05),\n",
       " ('neglectful', 8.052826542116283e-05),\n",
       " ('justify', 8.052826542116283e-05),\n",
       " ('goodman', 8.052826542116283e-05),\n",
       " ('unimaginable', 8.052826542116283e-05),\n",
       " ('insure', 8.052826542116283e-05),\n",
       " ('jewell', 8.052826542116283e-05),\n",
       " ('harness', 8.052826542116283e-05),\n",
       " ('reasonable', 8.052826542116283e-05),\n",
       " ('diagnostic', 8.052826542116283e-05),\n",
       " ('kacey', 8.052826542116283e-05),\n",
       " ('dove', 8.052826542116283e-05),\n",
       " ('let_alone', 8.052826542116283e-05),\n",
       " ('bumped', 8.052826542116283e-05),\n",
       " ('scouting', 8.052826542116283e-05),\n",
       " ('summarized', 8.052826542116283e-05),\n",
       " ('magna', 8.052826542116283e-05),\n",
       " ('gorfinkel', 8.052826542116283e-05),\n",
       " ('hind', 8.052826542116283e-05),\n",
       " ('carole', 8.052826542116283e-05),\n",
       " ('guis', 8.052826542116283e-05),\n",
       " ('gentry', 8.052826542116283e-05),\n",
       " ('killing', 8.052826542116283e-05),\n",
       " ('tiffani', 8.052826542116283e-05),\n",
       " ('strip_mall', 8.052826542116283e-05),\n",
       " ('barrage', 8.052826542116283e-05),\n",
       " ('impose', 8.052826542116283e-05),\n",
       " ('listening', 8.052826542116283e-05),\n",
       " ('naturalistic', 0.0),\n",
       " ('promenade', 0.0),\n",
       " ('mastercard', 0.0),\n",
       " ('groggy', 0.0),\n",
       " ('icing', 0.0),\n",
       " ('wolf', 0.0),\n",
       " ('horroible', 0.0),\n",
       " ('twll', 0.0),\n",
       " ('acdf', 0.0),\n",
       " ('incredulous', 0.0),\n",
       " ('interrogate', 0.0),\n",
       " ('fictitious', 0.0),\n",
       " ('reflux', 0.0),\n",
       " ('lowlife', 0.0),\n",
       " ('stalker', 0.0),\n",
       " ('smooshy', 0.0),\n",
       " ('immobilization', 0.0),\n",
       " ('tirelessly', 0.0),\n",
       " ('redrill', 0.0),\n",
       " ('fluish', 0.0),\n",
       " ('teusink', 0.0),\n",
       " ('uhc', 0.0),\n",
       " ('craftsmanship', 0.0),\n",
       " ('mummy', 0.0),\n",
       " ('unite', 0.0),\n",
       " ('csection', 0.0),\n",
       " ('grom', 0.0),\n",
       " ('shredded', 0.0),\n",
       " ('fasted', 0.0),\n",
       " ('frazzle', 0.0),\n",
       " ('prohibit', 0.0),\n",
       " ('windy', 0.0),\n",
       " ('wirh', 0.0),\n",
       " ('siram', 0.0),\n",
       " ('negotiation', 0.0),\n",
       " ('allude', 0.0),\n",
       " ('suction', 0.0),\n",
       " ('angelica', 0.0),\n",
       " ('esther', 0.0),\n",
       " ('purport', 0.0),\n",
       " ('paticularly', 0.0),\n",
       " ('frendly', 0.0),\n",
       " ('acupunturist', 0.0),\n",
       " ('axis', 0.0),\n",
       " ('hallquist', 0.0),\n",
       " ('diserf', 0.0),\n",
       " ('batra', 0.0),\n",
       " ('denisha', 0.0),\n",
       " ('biology', 0.0),\n",
       " ('preexist', 0.0),\n",
       " ('capital', 0.0),\n",
       " ('shand', 0.0),\n",
       " ('umana', 0.0),\n",
       " ('whiny', 0.0),\n",
       " ('inventory', 0.0),\n",
       " ('hmmmmmmm', 0.0),\n",
       " ('mellow', 0.0),\n",
       " ('smush', 0.0),\n",
       " ('flop', 0.0),\n",
       " ('residential', 0.0),\n",
       " ('futuristic', 0.0),\n",
       " ('template', 0.0),\n",
       " ('proficiency', 0.0),\n",
       " ('shoutout', 0.0),\n",
       " ('frick', 0.0),\n",
       " ('lard', 0.0),\n",
       " ('ny', 0.0),\n",
       " ('cessation', 0.0),\n",
       " ('peel', 0.0),\n",
       " ('giveaway', 0.0),\n",
       " ('peeling', 0.0),\n",
       " ('flushed', 0.0),\n",
       " ('robe', 0.0),\n",
       " ('flip_crack', 0.0),\n",
       " ('crack_flip', 0.0),\n",
       " ('rubbish', 0.0),\n",
       " ('donate', 0.0),\n",
       " ('rocco', 0.0),\n",
       " ('seizur', 0.0),\n",
       " ('constantine_george', 0.0),\n",
       " ('crying', 0.0),\n",
       " ('pronged', 0.0),\n",
       " ('enveloped', 0.0),\n",
       " ('splinter', 0.0),\n",
       " ('asia', 0.0),\n",
       " ('scottsdalechiro', 0.0),\n",
       " ('fabric', 0.0),\n",
       " ('beige', 0.0),\n",
       " ('pun_intend', 0.0),\n",
       " ('interpretation', 0.0),\n",
       " ('aptitude', 0.0),\n",
       " ('pensivy', 0.0),\n",
       " ('amazeballz', 0.0),\n",
       " ('prepp', 0.0),\n",
       " ('rivera', 0.0),\n",
       " ('consummate', 0.0),\n",
       " ('habitually', 0.0),\n",
       " ('darlene', 0.0),\n",
       " ('homey', 0.0),\n",
       " ('causation', 0.0),\n",
       " ('ticked', 0.0),\n",
       " ('approximate', 0.0),\n",
       " ('dock', 0.0),\n",
       " ('babesiosis', 0.0),\n",
       " ('pituitary', 0.0),\n",
       " ('monte', 0.0),\n",
       " ('bader', 0.0),\n",
       " ('phentermine', 0.0),\n",
       " ('heaviest', 0.0),\n",
       " ('bmi', 0.0),\n",
       " ('propel', 0.0),\n",
       " ('bureaucracy', 0.0),\n",
       " ('soloist', 0.0),\n",
       " ('exhibit', 0.0),\n",
       " ('principal', 0.0),\n",
       " ('cdc', 0.0),\n",
       " ('techie', 0.0),\n",
       " ('nhan', 0.0),\n",
       " ('vaccinated', 0.0),\n",
       " ('panda', 0.0),\n",
       " ('picc', 0.0),\n",
       " ('latest', 0.0),\n",
       " ('apsolute', 0.0),\n",
       " ('fatigued', 0.0),\n",
       " ('formulate', 0.0),\n",
       " ('checklist', 0.0),\n",
       " ('instudio', 0.0),\n",
       " ('arjomand', 0.0),\n",
       " ('suzanne', 0.0),\n",
       " ('carrington', 0.0),\n",
       " ('sanitizing', 0.0),\n",
       " ('pianist', 0.0),\n",
       " ('lace', 0.0),\n",
       " ('overexert', 0.0),\n",
       " ('babbey', 0.0),\n",
       " ('downtown_core', 0.0),\n",
       " ('chug', 0.0),\n",
       " ('achhhs', 0.0),\n",
       " ('unsecure', 0.0),\n",
       " ('pharm', 0.0),\n",
       " ('theft', 0.0),\n",
       " ('pitt', 0.0),\n",
       " ('vitullo', 0.0),\n",
       " ('hacking', 0.0),\n",
       " ('hardy', 0.0),\n",
       " ('dork', 0.0),\n",
       " ('unsecured', 0.0),\n",
       " ('applause', 0.0),\n",
       " ('nutty', 0.0),\n",
       " ('prod', 0.0),\n",
       " ('micah', 0.0),\n",
       " ('sonny', 0.0),\n",
       " ('icomplet', 0.0),\n",
       " ('seeking', 0.0),\n",
       " ('questioni', 0.0),\n",
       " ('mob', 0.0),\n",
       " ('wellpoint', 0.0),\n",
       " ('radically', 0.0),\n",
       " ('betina', 0.0),\n",
       " ('socal', 0.0),\n",
       " ('follower', 0.0),\n",
       " ('bandwagon', 0.0),\n",
       " ('klutz', 0.0),\n",
       " ('raptor', 0.0),\n",
       " ('reco', 0.0),\n",
       " ('kilimanjaro', 0.0),\n",
       " ('awwwsome', 0.0),\n",
       " ('iliopsoas', 0.0),\n",
       " ('carne', 0.0),\n",
       " ('appnt', 0.0),\n",
       " ('maccollum', 0.0),\n",
       " ('interrupted', 0.0),\n",
       " ('ibu', 0.0),\n",
       " ('ganesh', 0.0),\n",
       " ('uncleaned', 0.0),\n",
       " ('rochelle', 0.0),\n",
       " ('allergi', 0.0),\n",
       " ('abysmal', 0.0),\n",
       " ('finalizing', 0.0),\n",
       " ('stopping', 0.0),\n",
       " ('intuitiveness', 0.0),\n",
       " ('royally', 0.0),\n",
       " ('apron', 0.0),\n",
       " ('rejuvenating', 0.0),\n",
       " ('believable', 0.0),\n",
       " ('hero', 0.0),\n",
       " ('asana', 0.0),\n",
       " ('teamsuperbenji', 0.0),\n",
       " ('pardon', 0.0),\n",
       " ('sane', 0.0),\n",
       " ('specialization', 0.0),\n",
       " ('cima', 0.0),\n",
       " ('finch', 0.0),\n",
       " ('moth', 0.0),\n",
       " ('cremation', 0.0),\n",
       " ('af', 0.0),\n",
       " ('agey', 0.0),\n",
       " ('interfered', 0.0),\n",
       " ('scarborough', 0.0),\n",
       " ('academic', 0.0),\n",
       " ('noonish', 0.0),\n",
       " ('itme', 0.0),\n",
       " ('synthroid', 0.0),\n",
       " ('greisman', 0.0),\n",
       " ('morally', 0.0),\n",
       " ('expeditiously', 0.0),\n",
       " ('tilt', 0.0),\n",
       " ('simplifie', 0.0),\n",
       " ('welll', 0.0),\n",
       " ('rosin', 0.0),\n",
       " ...]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the model with the highest coherence and print the topics\n",
    "optimal_model = model_list[max(range(len(coherence_values)), key=coherence_values.__getitem__)]\n",
    "# model_topics = optimal_model.show_topics(formatted=False)\n",
    "# roo = dict(sorted(optimal_model.show_topics(num_topics=50, num_words=10,formatted=False),key=lambda x: (x[0]))))\n",
    "topic_list = []\n",
    "for x in sorted(optimal_model.show_topics(num_topics=50,num_words=10,formatted=False),key=lambda x: (x[0])):\n",
    "     topic_list.append(x[1])\n",
    "\n",
    "optimal_model.show_topic(0,topn=len(id2word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the dominant topic in each sentence\n",
    "One of the practical application of topic modeling is to determine what topic a given document is about.\n",
    "To find that, we find the topic number that has the highest percentage contribution in that document.\n",
    "\n",
    "The format_topics_sentences() function below nicely aggregates this information in a presentable table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #optimal_model[corpus[1]]\n",
    "# print(len(data))\n",
    "# print(len(corpus))\n",
    "# print(len(df_dominant_topic))\n",
    "# df_dominant_topic.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dominant_topic.to_pickle(\"df_dominant_topic.pkl\")\n",
    "# df_topic_sents_keywords.to_pickle(\"df_topic_sents_keywords.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A  = df_dominant_topic[['Dominant_Topic','Keywords']]  # prevelant to save topics first 10 words to CSV file\n",
    "B = A.drop_duplicates(subset='Dominant_Topic', keep=\"first\") \n",
    "B.sort_values('Dominant_Topic').to_csv(\"Keywords11.csv\",doublequote = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_matrix = np.zeros((50,len(corpus)))\n",
    "for i, row in enumerate(optimal_model[corpus]):\n",
    "    row = sorted(row, key=lambda x: (x[0]))\n",
    "    for topic,prop in row:\n",
    "        doc_topic_matrix[topic][i] = prop\n",
    "        \n",
    "top10_doc = []\n",
    "for x in doc_topic_matrix:\n",
    "    top10_doc.append([x for x in (-x).argsort()[:10]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('life', 0.08423256563053631), ('health', 0.04469318730874537), ('year', 0.037928813013367695), ('change', 0.03511032372362699), ('condition', 0.026896440650668384), ('treat', 0.020293122886133032), ('healthy', 0.02021259462071187), ('live', 0.017957803188919312), ('save', 0.017555161861813495), ('trust', 0.013689805121597681)]\n",
      "first arrive shea medical sick health get bad day pass diagnose year ago lyme_disease try conventional treatment nothing depress lose hope ever live normal life day google lyme literate doctor shea medical first display click link life forever change click immediately send online inquiry figure would hear someone next day minute receive phone call speak patient coordinator compassionate knowledgeable answer question send detailed information read listen remember bit surprised compassion never receive medical professional year fight disease soon listen presentation send know shea medical place need initial_consultation far exceed expectation doctor take time listen answer question clearly describe illness treatment shea medical save life cutting_edge integrative approach treat lyme_disease finally allow start live spend week friday clinic receive good care ever receive front office staff doctor everyone compassionate go ensure comfortable get support need get hard treatment start wheelchair walk assistance symptom better know keep get healthy healthy good treatment protocol treat lyme_disease give knowledge disease need keep remission forever_grateful entire staff shea medical forever change life anyone look treat lyme chronic illness receive good care fully recommend shea medical\n",
      "year ago learn medical treatment month would diabetic coma likely die diabetes diagnosis blood glucose know proper nutrition medication order war diabet side side drastic measure order tonya nutritionist spectacular tonya able explain importance proper nutrition offer list food diabetic friendly initially chart strict diet due severity condition stick strictly diet suggest result come month stable ever short tonya save life say lightly people rely doctor medication important overlook component diet nutrition ongoing stability due key component medication dr frye prescribe diet tonya suggest point result close normal glucose thank commitment receive dr frye tonya right team health battlefield make successful outcome make right choice proof result thank tanya frye tonya hidden_gem office ask let chart nutritional course feeling better also certify pilot know know stuff\n",
      "patient milne past say man md ever case complicate eventually turn lyme_disease lyme something mimic everything sun milne patiently take time search could fund limit sensitive informed cost thing offend time could get right time time treatment bad side_effect fault genetic weakness mine meet office first thing next morning work day squeeze schedule patient make sure come ok academy award md would give man intuitive insight truly gift save many md give encourage believe negative_review holistic care expensive want choose conventional western md desire man unique talent would miss other want integrative holistic_approach robert milne man\n",
      "write review thankful radoff staff alternative medical dr radoff initially begin treat teenage son provide healthcare entire family consider fairly educate biomedical alternative medical treatment endless intricacy treat autism adhd asthma allergy modaliti available count top individual need unique set tool treat particular condition size_fit cure condition completely understand costly pay pocket try something work say help guidance radoff able rationally pick choose treatment thereby save incredible amount time money life radoff able utilize expertise experience expertise impressive network colleague remain open understanding importance parental intuition intensive therapy prior year teen change severely low function autistic physically emotionally mentally low function well adjust young man path change need hour supervision real opportunity independent life reenroll high_school first intern job possibly drive live independently someday long difficult journey promise outcome without_doubt worth second dollar opinion consult numerous doctor incredibly disappointed lack knowledge lack desire obtain knowledge overall pessimistic attitude possibility disappointing doctor medical insurance community cost effective treat child know much could do need medical professional help guide heal forever indebt radoff son life potential everyday good word advise offer stay open_minded educate continue educate look little improvement add time trust parental intuition never give great book read parent autistic heal new childhood epidemic autism adhd asthma allergy groundbreak program disorder\n"
     ]
    }
   ],
   "source": [
    "print(topic_list[0])\n",
    "print('\\n'.join([data[i] for i in top10_doc[0][:4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>call, receive, send, return, request, referral...</td>\n",
       "      <td>never know awesome service staff shit hit fan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>wait, hour, room, minute, long, time, sit, hal...</td>\n",
       "      <td>adult year become try true doctor snob wait ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>surgery, ray, foot, procedure, week, hand, bre...</td>\n",
       "      <td>johnsen treat sports_relat knee injury profess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>doctor, find, office, patient, nurse, talk, fi...</td>\n",
       "      <td>absolute_worst doctor office vegas wait hour e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>surgery, ray, foot, procedure, week, hand, bre...</td>\n",
       "      <td>go liu seem great doctor office staff rude try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>feel, make, question, answer, comfortable, rus...</td>\n",
       "      <td>owner joe thorough care client make feel comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>great, staff, friendly, experience, job, highl...</td>\n",
       "      <td>jone great personable really spend time get kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>chiropractor, neck, chiropractic, back, adjust...</td>\n",
       "      <td>second baby attempt hit gym get back shape bod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0791</td>\n",
       "      <td>good, recommend, find, friend, feel, wife, hap...</td>\n",
       "      <td>lee recommend friend bother shoulder pain weig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>massage, therapist, feel, session, body, press...</td>\n",
       "      <td>impressed search good massage arrive phoenix a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>time, long, spend, wait, waste, short, busy, d...</td>\n",
       "      <td>bad wait time always long urgent care facility...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>prescription, doctor, medication, med, give, p...</td>\n",
       "      <td>go pain center arizona matthew doust treat mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>place, nice, good, great, clean, awesome, supe...</td>\n",
       "      <td>office awesome paint everywhere fun cartoon ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>care, health, urgent, provider, primary, patie...</td>\n",
       "      <td>turntable first open fantastic however go way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>bad, place, people, rude, horrible, front_desk...</td>\n",
       "      <td>place absolutely horrible receptionist try avo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>place, nice, good, great, clean, awesome, supe...</td>\n",
       "      <td>regret go dr skabo refer friend never let go w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>physical_therapy, therapist, therapy, exercise...</td>\n",
       "      <td>year ago need physical_therapy know henceforth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>professional, extremely, knowledgeable, recomm...</td>\n",
       "      <td>great friendly people really care recovery see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>class, studio, room, clean, water, instructor,...</td>\n",
       "      <td>review nurse_practitioner courtney drive minut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>result, test, blood, lab, work, order, follow,...</td>\n",
       "      <td>tice excellent doctor treat metabolic hormonal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             0             8.0              0.0726   \n",
       "1             1            18.0              0.0615   \n",
       "2             2            31.0              0.0660   \n",
       "3             3            12.0              0.0611   \n",
       "4             4            31.0              0.0481   \n",
       "5             5            28.0              0.0462   \n",
       "6             6            45.0              0.0547   \n",
       "7             7            39.0              0.1035   \n",
       "8             8            13.0              0.0791   \n",
       "9             9            41.0              0.0869   \n",
       "10           10            30.0              0.0528   \n",
       "11           11            49.0              0.1020   \n",
       "12           12            16.0              0.0757   \n",
       "13           13             5.0              0.1320   \n",
       "14           14            34.0              0.0670   \n",
       "15           15            16.0              0.0710   \n",
       "16           16            43.0              0.1423   \n",
       "17           17            32.0              0.0539   \n",
       "18           18            47.0              0.0604   \n",
       "19           19            36.0              0.2139   \n",
       "\n",
       "                                             Keywords  \\\n",
       "0   call, receive, send, return, request, referral...   \n",
       "1   wait, hour, room, minute, long, time, sit, hal...   \n",
       "2   surgery, ray, foot, procedure, week, hand, bre...   \n",
       "3   doctor, find, office, patient, nurse, talk, fi...   \n",
       "4   surgery, ray, foot, procedure, week, hand, bre...   \n",
       "5   feel, make, question, answer, comfortable, rus...   \n",
       "6   great, staff, friendly, experience, job, highl...   \n",
       "7   chiropractor, neck, chiropractic, back, adjust...   \n",
       "8   good, recommend, find, friend, feel, wife, hap...   \n",
       "9   massage, therapist, feel, session, body, press...   \n",
       "10  time, long, spend, wait, waste, short, busy, d...   \n",
       "11  prescription, doctor, medication, med, give, p...   \n",
       "12  place, nice, good, great, clean, awesome, supe...   \n",
       "13  care, health, urgent, provider, primary, patie...   \n",
       "14  bad, place, people, rude, horrible, front_desk...   \n",
       "15  place, nice, good, great, clean, awesome, supe...   \n",
       "16  physical_therapy, therapist, therapy, exercise...   \n",
       "17  professional, extremely, knowledgeable, recomm...   \n",
       "18  class, studio, room, clean, water, instructor,...   \n",
       "19  result, test, blood, lab, work, order, follow,...   \n",
       "\n",
       "                                                 Text  \n",
       "0   never know awesome service staff shit hit fan ...  \n",
       "1   adult year become try true doctor snob wait ex...  \n",
       "2   johnsen treat sports_relat knee injury profess...  \n",
       "3   absolute_worst doctor office vegas wait hour e...  \n",
       "4   go liu seem great doctor office staff rude try...  \n",
       "5   owner joe thorough care client make feel comfo...  \n",
       "6   jone great personable really spend time get kn...  \n",
       "7   second baby attempt hit gym get back shape bod...  \n",
       "8   lee recommend friend bother shoulder pain weig...  \n",
       "9   impressed search good massage arrive phoenix a...  \n",
       "10  bad wait time always long urgent care facility...  \n",
       "11  go pain center arizona matthew doust treat mot...  \n",
       "12  office awesome paint everywhere fun cartoon ke...  \n",
       "13  turntable first open fantastic however go way ...  \n",
       "14  place absolutely horrible receptionist try avo...  \n",
       "15  regret go dr skabo refer friend never let go w...  \n",
       "16  year ago need physical_therapy know henceforth...  \n",
       "17  great friendly people really care recovery see...  \n",
       "18  review nurse_practitioner courtney drive minut...  \n",
       "19  tice excellent doctor treat metabolic hormonal...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic_Roo\n",
    "for i in [5,7,9]:\n",
    "    if i != 5:\n",
    "        df_topic_Roo = df_topic_Roo.append(format_topics_sentences(ldamodel=model_list[i], corpus=corpus, texts=data))\n",
    "\n",
    "# Format\n",
    "    df_dominant_topic_Roo[i] = df_topic_sents_keywords.reset_index()\n",
    "    df_dominant_topic_Roo[i].columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dominant_topic.iloc[7][4])\n",
    "print(sorted(optimal_model[corpus][4], key=lambda x: x[1], reverse= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dominant_topic.iloc[10,3])\n",
    "print(df_dominant_topic.iloc[5,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model.show_topic(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most representative document for each topic\n",
    "Sometimes just the topic keywords may not be enough to make sense of what a topic is about. So, to help with understanding the topic, you can find the documents a given topic has contributed to the most and infer the topic by reading that document. Whew!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent_topics_sorteddf_mallet.iloc[20][2])\n",
    "print(sent_topics_sorteddf_mallet.iloc[20][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic distribution across documents\n",
    "Finally, we want to understand the volume and distribution of topics in order to judge how widely it was discussed. The below table exposes that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [] \n",
    "a = a.append('333')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
